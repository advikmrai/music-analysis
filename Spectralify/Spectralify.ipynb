{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3af66-9607-4cbb-890a-c57025e87d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spectralify.py - Audio Analysis Tool\n",
    "-----------------------------------\n",
    "A modular tool for extracting audio features from music files.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import warnings\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "# Audio processing imports\n",
    "import librosa\n",
    "from mutagen.flac import FLAC\n",
    "from mutagen.mp3 import MP3\n",
    "from mutagen.wave import WAVE\n",
    "from mutagen.aac import AAC\n",
    "from mutagen.aiff import AIFF\n",
    "\n",
    "# Data handling imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('spectralify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfb9c9-a05f-4708-a5fc-93292c4637a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration and Constants\n",
    "# ============================================================================\n",
    "\n",
    "class AudioFormats:\n",
    "    \"\"\"Audio format configurations and constants\"\"\"\n",
    "    \n",
    "    FORMATS = {\n",
    "        '.flac': {'mime_type': 'audio/flac', 'parser': FLAC},\n",
    "        '.mp3': {'mime_type': 'audio/mp3', 'parser': MP3},\n",
    "        '.wav': {'mime_type': 'audio/wav', 'parser': WAVE},\n",
    "        '.aac': {'mime_type': 'audio/aac', 'parser': AAC},\n",
    "        '.aiff': {'mime_type': 'audio/aiff', 'parser': AIFF},\n",
    "        '.wma': {'mime_type': 'audio/wma', 'parser': None}\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def is_supported(cls, file_extension):\n",
    "        \"\"\"Check if file extension is supported\"\"\"\n",
    "        return file_extension.lower() in cls.FORMATS\n",
    "    \n",
    "    @classmethod\n",
    "    def get_parser(cls, file_extension):\n",
    "        \"\"\"Get parser for file extension\"\"\"\n",
    "        return cls.FORMATS.get(file_extension.lower(), {}).get('parser')\n",
    "    \n",
    "    @classmethod\n",
    "    def get_mime_type(cls, file_extension):\n",
    "        \"\"\"Get MIME type for file extension\"\"\"\n",
    "        return cls.FORMATS.get(file_extension.lower(), {}).get('mime_type', 'audio/unknown')\n",
    "\n",
    "\n",
    "class MetadataTags:\n",
    "    \"\"\"Constants for metadata tag mapping\"\"\"\n",
    "    \n",
    "    # Common tag mapping for audio formats\n",
    "    COMMON_TAGS = {\n",
    "        'title': 'Title',\n",
    "        'artist': 'Artist',\n",
    "        'album': 'Album',\n",
    "        # Common variations\n",
    "        'TITLE': 'Title',\n",
    "        'ARTIST': 'Artist',\n",
    "        'ALBUM': 'Album'\n",
    "    }\n",
    "    \n",
    "    # ID3-specific tag mapping\n",
    "    ID3_TAGS = {\n",
    "        'TIT2': 'Title',     # Title/songname/content description\n",
    "        'TPE1': 'Artist',    # Lead performer(s)/Soloist(s)\n",
    "        'TALB': 'Album',     # Album/Movie/Show title\n",
    "        # Alternate tag names for backwards compatibility\n",
    "        'TT2': 'Title',      # ID3v2.2 equivalent of TIT2\n",
    "        'TP1': 'Artist',     # ID3v2.2 equivalent of TPE1\n",
    "        'TAL': 'Album',      # ID3v2.2 equivalent of TALB\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f191bfd-1fb3-40c0-aa3d-0f708949cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Utility Classes\n",
    "# ============================================================================\n",
    "\n",
    "class ProgressTracker:\n",
    "    \"\"\"Track and display progress for long-running operations\"\"\"\n",
    "    \n",
    "    def __init__(self, total: int, description: str = \"Processing\", bar_length: int = 50):\n",
    "        self.total = total\n",
    "        self.current = 0\n",
    "        self.start_time = time.time()\n",
    "        self.description = description\n",
    "        self.bar_length = bar_length\n",
    "        \n",
    "    def update(self, amount: int = 1) -> None:\n",
    "        \"\"\"Update progress and display the progress bar\"\"\"\n",
    "        self.current += amount\n",
    "        self._display_progress()\n",
    "        \n",
    "    def _format_time(self, seconds: float) -> str:\n",
    "        \"\"\"Convert seconds to a readable format\"\"\"\n",
    "        return str(timedelta(seconds=int(seconds)))\n",
    "        \n",
    "    def _calculate_eta(self) -> Optional[float]:\n",
    "        \"\"\"Calculate estimated time remaining\"\"\"\n",
    "        if self.current == 0:\n",
    "            return None\n",
    "        \n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        items_per_second = self.current / elapsed_time\n",
    "        remaining_items = self.total - self.current\n",
    "        \n",
    "        return remaining_items / items_per_second if items_per_second > 0 else None\n",
    "        \n",
    "    def _display_progress(self) -> None:\n",
    "        \"\"\"Display progress bar with time estimates\"\"\"\n",
    "        percentage = min(100, (self.current / self.total) * 100)\n",
    "        filled_length = int(self.bar_length * self.current // self.total)\n",
    "        \n",
    "        # Create the progress bar\n",
    "        bar = '█' * filled_length + '░' * (self.bar_length - filled_length)\n",
    "        \n",
    "        # Calculate time metrics\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        eta = self._calculate_eta()\n",
    "        \n",
    "        # Format the progress message\n",
    "        progress_msg = (\n",
    "            f'\\r{self.description}: |{bar}| '\n",
    "            f'{percentage:>6.2f}% ({self.current}/{self.total}) '\n",
    "            f'[{self._format_time(elapsed_time)} elapsed'\n",
    "        )\n",
    "        \n",
    "        if eta is not None:\n",
    "            progress_msg += f' | ETA: {self._format_time(eta)}]'\n",
    "        else:\n",
    "            progress_msg += ']'\n",
    "            \n",
    "        # Print the progress\n",
    "        print(progress_msg, end='', flush=True)\n",
    "        \n",
    "        # Print newline if complete\n",
    "        if self.current >= self.total:\n",
    "            print(f\"\\nCompleted in {self._format_time(elapsed_time)}\")\n",
    "\n",
    "\n",
    "class ResourceManager:\n",
    "    \"\"\"Context manager for resource-intensive operations\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def __enter__(self):\n",
    "        logger.debug(f\"Starting resource-intensive operation: {self.name}\")\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        logger.debug(f\"Completed operation: {self.name}, cleaning up resources\")\n",
    "        gc.collect()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e663e-b7ae-40e0-8643-05b30f2d7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Metadata Extraction\n",
    "# ============================================================================\n",
    "\n",
    "class MetadataExtractor:\n",
    "    \"\"\"Base class for metadata extraction\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_extractor(cls, file_path):\n",
    "        \"\"\"Factory method to create appropriate metadata extractor\"\"\"\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        parser_class = AudioFormats.get_parser(ext)\n",
    "        \n",
    "        if parser_class == MP3:\n",
    "            return MP3MetadataExtractor()\n",
    "        else:\n",
    "            return DefaultMetadataExtractor()\n",
    "    \n",
    "    def extract(self, file_path):\n",
    "        \"\"\"Extract metadata from file\"\"\"\n",
    "        try:\n",
    "            ext = os.path.splitext(file_path)[1].lower()\n",
    "            parser_class = AudioFormats.get_parser(ext)\n",
    "            \n",
    "            if parser_class:\n",
    "                audio_meta = parser_class(file_path)\n",
    "                metadata = self._extract_from_meta(audio_meta)\n",
    "                \n",
    "                # Fill in missing values with basic metadata\n",
    "                for key in ['Title', 'Artist', 'Album']:\n",
    "                    if not metadata.get(key):\n",
    "                        basic_metadata = self._extract_from_path(file_path)\n",
    "                        metadata[key] = basic_metadata.get(key, f'Unknown {key}')\n",
    "                \n",
    "                return metadata\n",
    "            else:\n",
    "                return self._extract_from_path(file_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Metadata extraction error for {file_path}: {str(e)}\")\n",
    "            return self._extract_from_path(file_path)\n",
    "    \n",
    "    def _extract_from_meta(self, audio_meta):\n",
    "        \"\"\"Extract metadata from audio metadata object\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "    \n",
    "    def _extract_from_path(self, file_path):\n",
    "        \"\"\"Extract basic metadata from file path\"\"\"\n",
    "        metadata = {\n",
    "            'Title': 'Unknown Title',\n",
    "            'Album': 'Unknown Album',\n",
    "            'Artist': 'Unknown Artist'\n",
    "        }\n",
    "        \n",
    "        if file_path:\n",
    "            try:\n",
    "                path = Path(file_path)\n",
    "                \n",
    "                # Get title from filename\n",
    "                metadata['Title'] = path.stem\n",
    "                \n",
    "                # Get artist and album from directory structure\n",
    "                parts = list(path.parts)\n",
    "                if len(parts) > 2:\n",
    "                    # Look for year pattern in album folder name\n",
    "                    album_dir = parts[-2]\n",
    "                    if '[' in album_dir and ']' in album_dir:\n",
    "                        # Extract album name without year\n",
    "                        metadata['Album'] = album_dir.split(']')[-1].strip()\n",
    "                    else:\n",
    "                        metadata['Album'] = album_dir\n",
    "                    \n",
    "                    metadata['Artist'] = parts[-3]\n",
    "                elif len(parts) > 1:\n",
    "                    metadata['Album'] = parts[-2]\n",
    "                \n",
    "                # Clean up values\n",
    "                for key in metadata:\n",
    "                    if metadata[key]:\n",
    "                        # Remove file extensions, underscores, excessive spaces\n",
    "                        cleaned = metadata[key].replace('_', ' ').strip()\n",
    "                        # Remove common file prefixes/numbers\n",
    "                        if key == 'Title':\n",
    "                            cleaned = ' '.join(cleaned.split()[1:]) if cleaned.split() and cleaned.split()[0].isdigit() else cleaned\n",
    "                        metadata[key] = cleaned\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing file path metadata: {str(e)}\")\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "\n",
    "class MP3MetadataExtractor(MetadataExtractor):\n",
    "    \"\"\"Extract metadata from MP3 files\"\"\"\n",
    "    \n",
    "    def _extract_from_meta(self, audio_meta):\n",
    "        \"\"\"Extract metadata specifically from MP3 files\"\"\"\n",
    "        metadata = {\n",
    "            'Title': '',\n",
    "            'Artist': '',\n",
    "            'Album': '',\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            if hasattr(audio_meta, 'tags') and audio_meta.tags:\n",
    "                # Standard ID3 tags\n",
    "                for id3_key, meta_key in MetadataTags.ID3_TAGS.items():\n",
    "                    if id3_key in audio_meta.tags:\n",
    "                        tag_value = audio_meta.tags[id3_key]\n",
    "                        if hasattr(tag_value, 'text'):\n",
    "                            metadata[meta_key] = str(tag_value.text[0])\n",
    "                        else:\n",
    "                            metadata[meta_key] = str(tag_value)\n",
    "                \n",
    "                # Try alternate tag names if standard ones aren't found\n",
    "                if not metadata['Title'] and 'TIT1' in audio_meta.tags:\n",
    "                    metadata['Title'] = str(audio_meta.tags['TIT1'].text[0])\n",
    "                if not metadata['Artist'] and 'TPE2' in audio_meta.tags:\n",
    "                    metadata['Artist'] = str(audio_meta.tags['TPE2'].text[0])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"MP3 metadata extraction error: {str(e)}\")\n",
    "            \n",
    "        return metadata\n",
    "\n",
    "\n",
    "class DefaultMetadataExtractor(MetadataExtractor):\n",
    "    \"\"\"Default metadata extractor for non-MP3 formats\"\"\"\n",
    "    \n",
    "    def _extract_from_meta(self, audio_meta):\n",
    "        \"\"\"Extract metadata from non-MP3 audio files\"\"\"\n",
    "        metadata = {\n",
    "            'Title': '',\n",
    "            'Artist': '',\n",
    "            'Album': '',\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            if hasattr(audio_meta, 'tags'):\n",
    "                for tag_key, tag_value in audio_meta.tags.items():\n",
    "                    # Convert tag key to lowercase for consistent matching\n",
    "                    tag_lower = tag_key.lower()\n",
    "                    \n",
    "                    # Try to match with known tag mappings\n",
    "                    for known_key, meta_key in MetadataTags.COMMON_TAGS.items():\n",
    "                        if known_key.lower() in tag_lower:\n",
    "                            # Handle different tag value formats\n",
    "                            if isinstance(tag_value, list):\n",
    "                                metadata[meta_key] = str(tag_value[0])\n",
    "                            elif isinstance(tag_value, (str, int, float)):\n",
    "                                metadata[meta_key] = str(tag_value)\n",
    "                            else:\n",
    "                                try:\n",
    "                                    metadata[meta_key] = str(tag_value)\n",
    "                                except:\n",
    "                                    continue\n",
    "                            break\n",
    "        except Exception as e:\n",
    "            logger.error(f\"General metadata extraction error: {str(e)}\")\n",
    "        \n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc53b38-8d18-4390-9b56-d0bfa896326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Audio Feature Extraction\n",
    "# ============================================================================\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Base class for audio feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, audio_data, sample_rate):\n",
    "        self.audio_data = audio_data\n",
    "        self.sr = sample_rate\n",
    "        self.features = {}\n",
    "    \n",
    "    def extract_all(self):\n",
    "        \"\"\"Extract all features and return as dictionary\"\"\"\n",
    "        # Extract each feature group\n",
    "        self.extract_basic_features()\n",
    "        self.extract_spectral_features()\n",
    "        self.extract_rhythm_features()\n",
    "        self.extract_harmonic_features()\n",
    "        self.extract_instrument_features()\n",
    "        self.extract_vocal_features()\n",
    "        self.extract_emotional_features()\n",
    "        self.extract_pitch_features()\n",
    "        \n",
    "        # Ensure all float values are Python float type (not numpy)\n",
    "        for key in self.features:\n",
    "            if isinstance(self.features[key], (np.float32, np.float64)):\n",
    "                self.features[key] = float(self.features[key])\n",
    "        \n",
    "        return self.features\n",
    "    \n",
    "    def extract_basic_features(self):\n",
    "        \"\"\"Extract basic temporal features\"\"\"\n",
    "        self.features['Duration_Seconds'] = len(self.audio_data) / self.sr\n",
    "        return self\n",
    "    \n",
    "    def extract_spectral_features(self):\n",
    "        \"\"\"Extract spectral features\"\"\"\n",
    "        with ResourceManager(\"Spectral Features\"):\n",
    "            # Compute STFT\n",
    "            S = librosa.stft(self.audio_data)\n",
    "            \n",
    "            # Compute spectral features\n",
    "            spectral_centroids = librosa.feature.spectral_centroid(S=np.abs(S), sr=self.sr)[0]\n",
    "            spectral_rolloff = librosa.feature.spectral_rolloff(S=np.abs(S), sr=self.sr)[0]\n",
    "            spectral_bandwidth = librosa.feature.spectral_bandwidth(S=np.abs(S), sr=self.sr)[0]\n",
    "            spectral_contrast = librosa.feature.spectral_contrast(S=np.abs(S), sr=self.sr)\n",
    "            \n",
    "            # Add features to dictionary\n",
    "            self._add_mean_std_features('Spectral_Centroid', spectral_centroids)\n",
    "            self._add_mean_std_features('Spectral_Rolloff', spectral_rolloff)\n",
    "            self._add_mean_std_features('Spectral_Bandwidth', spectral_bandwidth)\n",
    "            \n",
    "            self.features['Spectral_Contrast_Mean'] = float(np.mean(spectral_contrast))\n",
    "            self.features['Spectral_Contrast_Std'] = float(np.std(spectral_contrast))\n",
    "            \n",
    "            # Compute spectral entropy\n",
    "            S_norm = np.abs(S) / (np.sum(np.abs(S)) + 1e-10)\n",
    "            self.features['Spectral_Entropy'] = float(-np.sum(S_norm * np.log2(S_norm + 1e-10)))\n",
    "            \n",
    "            # Normalize spectral entropy\n",
    "            max_entropy = -np.log2(1.0/len(S))  # Maximum possible entropy\n",
    "            self.features['Spectral_Entropy'] = float(min(1.0, self.features['Spectral_Entropy'] / max_entropy))\n",
    "            \n",
    "            # Compute spectral flatness\n",
    "            self.features['Spectral_Flatness'] = float(np.mean(librosa.feature.spectral_flatness(y=self.audio_data)))\n",
    "            self.features['Spectral_Flatness'] = float(min(1.0, self.features['Spectral_Flatness']))\n",
    "            \n",
    "            # Compute zero crossing rate\n",
    "            zcr = librosa.feature.zero_crossing_rate(self.audio_data)[0]\n",
    "            self.features['Zero_Crossing_Rate_Mean'] = float(np.mean(zcr))\n",
    "            self.features['Zero_Crossing_Rate_Std'] = float(np.std(zcr))\n",
    "            \n",
    "            # Reassigned spectrogram features\n",
    "            freqs, times, mags = librosa.reassigned_spectrogram(self.audio_data)\n",
    "            self.features['Reassigned_Frequency_Mean'] = float(np.mean(freqs[np.abs(mags) > np.median(np.abs(mags))]))\n",
    "            self.features['Reassigned_Magnitude_Mean'] = float(np.mean(mags))\n",
    "            \n",
    "            # Polynomial spectral coefficients\n",
    "            poly_order = 4\n",
    "            freqs = librosa.fft_frequencies(sr=self.sr)\n",
    "            poly_coeffs = np.polyfit(np.arange(len(freqs)), np.mean(np.abs(S), axis=1), poly_order)\n",
    "            for i, coeff in enumerate(poly_coeffs):\n",
    "                self.features[f'Poly_Coefficient_{i+1}'] = float(coeff)\n",
    "            \n",
    "            # Bass prominence\n",
    "            bass_band = librosa.fft_frequencies(sr=self.sr) <= 250\n",
    "            self.features['Bass_Prominence'] = float(np.mean(np.abs(S)[bass_band]) / np.mean(np.abs(S)))\n",
    "            \n",
    "            # MFCC features with deltas\n",
    "            mfccs_all = librosa.feature.mfcc(y=self.audio_data, sr=self.sr, n_mfcc=13)\n",
    "            mfcc_deltas = librosa.feature.delta(mfccs_all)\n",
    "            mfcc_delta2 = librosa.feature.delta(mfccs_all, order=2)\n",
    "            \n",
    "            # MFCC coefficients with deltas and delta2s\n",
    "            for i, (mfcc, delta, delta2) in enumerate(zip(mfccs_all, mfcc_deltas, mfcc_delta2)):\n",
    "                self.features.update({\n",
    "                    f'MFCC_{i+1}_Mean': float(np.mean(mfcc)),\n",
    "                    f'MFCC_{i+1}_Std': float(np.std(mfcc)),\n",
    "                    f'MFCC_{i+1}_Delta_Mean': float(np.mean(delta)),\n",
    "                    f'MFCC_{i+1}_Delta_Std': float(np.std(delta)),\n",
    "                    f'MFCC_{i+1}_Delta2_Mean': float(np.mean(delta2)),\n",
    "                    f'MFCC_{i+1}_Delta2_Std': float(np.std(delta2))\n",
    "                })\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def extract_harmonic_features(self):\n",
    "        \"\"\"Extract harmonic features\"\"\"\n",
    "        with ResourceManager(\"Harmonic Features\"):\n",
    "            # Harmonic-percussive source separation\n",
    "            y_harmonic, y_percussive = librosa.effects.hpss(self.audio_data)\n",
    "            \n",
    "            # Harmonic features\n",
    "            self.features['Harmonic_Energy'] = float(np.mean(np.abs(y_harmonic)))\n",
    "            self.features['Percussive_Energy'] = float(np.mean(np.abs(y_percussive)))\n",
    "            \n",
    "            harmonic_energy = np.mean(y_harmonic**2)\n",
    "            percussive_energy = np.mean(y_percussive**2)\n",
    "            self.features['Harmonic_Ratio'] = float(harmonic_energy/(percussive_energy + 1e-10))\n",
    "            self.features['Tonal_Energy_Ratio'] = float(np.sum(y_harmonic**2) / (np.sum(self.audio_data**2) + 1e-10))\n",
    "            \n",
    "            # Chroma features\n",
    "            chroma = librosa.feature.chroma_cqt(y=y_harmonic, sr=self.sr)\n",
    "            self.features['Chroma_Mean'] = float(np.mean(chroma))\n",
    "            self.features['Chroma_Std'] = float(np.std(chroma))\n",
    "            \n",
    "            # Add Harmonic_Salience calculation\n",
    "            self.features['Harmonic_Salience'] = float(np.mean(np.abs(y_harmonic)))\n",
    "        \n",
    "            # Key detection\n",
    "            key, mode, confidence = self._detect_key(chroma, y_harmonic)\n",
    "            self.features['Estimated_Key'] = f\"{key} {mode}\"\n",
    "            self.features['Key_Confidence'] = float(confidence)\n",
    "            \n",
    "            # Tonnetz features\n",
    "            tonnetz = librosa.feature.tonnetz(y=y_harmonic, sr=self.sr)\n",
    "            for i in range(6):\n",
    "                self.features[f'Tonnetz_{i+1}'] = float(np.mean(tonnetz[i]))\n",
    "            \n",
    "            # Variable-Q transform features\n",
    "            VQT = librosa.vqt(self.audio_data, sr=self.sr)\n",
    "            self.features['VQT_Mean'] = float(np.mean(np.abs(VQT)))\n",
    "            self.features['VQT_Std'] = float(np.std(np.abs(VQT)))\n",
    "\n",
    "            # HPSS metrics\n",
    "            self.features['HPSS_Harmonic_Mean'] = float(np.mean(np.abs(y_harmonic)))\n",
    "            self.features['HPSS_Percussive_Mean'] = float(np.mean(np.abs(y_percussive)))\n",
    "            self.features['HPSS_Ratio'] = float(np.sum(np.abs(y_harmonic)) / (np.sum(np.abs(y_percussive)) + 1e-8))\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def extract_rhythm_features(self):\n",
    "        \"\"\"Extract rhythm and beat-related features\"\"\"\n",
    "        with ResourceManager(\"Rhythm Features\"):\n",
    "            # Onset detection\n",
    "            onset_env = librosa.onset.onset_strength(y=self.audio_data, sr=self.sr)\n",
    "            \n",
    "            # Beat tracking\n",
    "            tempo, beats = librosa.beat.beat_track(y=self.audio_data, sr=self.sr)\n",
    "            self.features['Tempo_BPM'] = float(tempo.item())\n",
    "            \n",
    "            # Calculate beat statistics if beats were found\n",
    "            if len(beats) > 1:\n",
    "                beat_times = librosa.frames_to_time(beats, sr=self.sr)\n",
    "                beat_intervals = np.diff(beat_times)\n",
    "                self.features['Beat_Regularity'] = float(1.0 / (np.std(beat_intervals) + 1e-6))\n",
    "                self.features['Beat_Density'] = float(len(beats) / self.features['Duration_Seconds'])\n",
    "                self.features['Beat_Strength'] = float(np.mean(onset_env))\n",
    "                \n",
    "                # Calculate groove metrics\n",
    "                groove = librosa.feature.tempogram(onset_envelope=onset_env, sr=self.sr)\n",
    "                self.features['Groove_Consistency'] = float(1.0 / (np.std(groove, axis=1).mean() + 1e-6))\n",
    "            else:\n",
    "                self.features['Beat_Regularity'] = 0.0\n",
    "                self.features['Beat_Density'] = 0.0\n",
    "                self.features['Beat_Strength'] = 0.0\n",
    "                self.features['Groove_Consistency'] = 0.0\n",
    "            \n",
    "            # Onset features\n",
    "            onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=self.sr)\n",
    "            self.features['Onset_Rate'] = float(len(onset_frames) / self.features['Duration_Seconds'])\n",
    "            self.features['Onset_Strength_Mean'] = float(np.mean(onset_env))\n",
    "            self.features['Onset_Strength_Std'] = float(np.std(onset_env))\n",
    "            \n",
    "            # Tempogram features\n",
    "            ftempo = librosa.feature.fourier_tempogram(y=self.audio_data, sr=self.sr)\n",
    "            self.features['Tempogram_Mean'] = float(np.mean(np.abs(ftempo)))\n",
    "            self.features['Tempogram_Std'] = float(np.std(np.abs(ftempo)))\n",
    "            \n",
    "            # Additional tempogram ratio\n",
    "            tgram = librosa.feature.tempogram(onset_envelope=onset_env, sr=self.sr)\n",
    "            self.features['Tempogram_Ratio'] = float(np.max(np.mean(tgram, axis=1)) / np.mean(tgram))\n",
    "            \n",
    "            # Pulse clarity\n",
    "            pulse = librosa.beat.plp(onset_envelope=onset_env, sr=self.sr)\n",
    "            self.features['Pulse_Clarity'] = float(min(1.0, np.mean(pulse)))\n",
    "            \n",
    "            # Segment features\n",
    "            boundaries = librosa.onset.onset_detect(onset_envelope=onset_env, sr=self.sr)\n",
    "            boundary_times = librosa.frames_to_time(boundaries, sr=self.sr)\n",
    "\n",
    "            # Calculate segment statistics\n",
    "            self.features['Segment_Count'] = float(len(boundary_times))\n",
    "            if len(boundary_times) > 0:\n",
    "                self.features['Average_Segment_Duration'] = float(np.mean(np.diff(boundary_times))) if len(boundary_times) > 1 else 0.0\n",
    "                self.features['Segment_Duration_Std'] = float(np.std(np.diff(boundary_times))) if len(boundary_times) > 1 else 0.0\n",
    "                self.features['First_Segment_Time'] = float(boundary_times[0])\n",
    "                self.features['Last_Segment_Time'] = float(boundary_times[-1])\n",
    "            else:\n",
    "                self.features['Average_Segment_Duration'] = 0.0\n",
    "                self.features['Segment_Duration_Std'] = 0.0\n",
    "                self.features['First_Segment_Time'] = 0.0\n",
    "                self.features['Last_Segment_Time'] = 0.0\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def extract_instrument_features(self):\n",
    "        \"\"\"Extract instrument-specific features\"\"\"\n",
    "        with ResourceManager(\"Instrument Features\"):\n",
    "            # Sub-bands for different instruments\n",
    "            bands = {\n",
    "                'bass': (20, 250),\n",
    "                'kick_drum': (40, 100),\n",
    "                'snare': (120, 600),\n",
    "                'cymbals': (2000, 16000),\n",
    "                'electric_guitar': (400, 4000),\n",
    "                'vocals': (200, 4000),\n",
    "                'synthesizer': (100, 8000)\n",
    "            }\n",
    "            \n",
    "            # Calculate normalized band energies\n",
    "            S = librosa.stft(self.audio_data)\n",
    "            freqs = librosa.fft_frequencies(sr=self.sr)\n",
    "            \n",
    "            for instrument, (low, high) in bands.items():\n",
    "                band_mask = np.logical_and(freqs >= low, freqs <= high)\n",
    "                band_energy = np.mean(np.abs(S)[band_mask])\n",
    "                total_energy = np.mean(np.abs(S))\n",
    "                self.features[f'{instrument}_presence'] = float(band_energy / (total_energy + 1e-8))\n",
    "            \n",
    "            # Harmonic-percussive source separation for instrument detection\n",
    "            y_harmonic, y_percussive = librosa.effects.hpss(self.audio_data)\n",
    "            \n",
    "            # Guitar detection using harmonic content\n",
    "            self.features['guitar_distortion'] = float(np.mean(librosa.feature.spectral_flatness(y=y_harmonic)))\n",
    "            \n",
    "            # Drum detection using percussive content\n",
    "            self.features['drum_prominence'] = float(np.mean(np.abs(y_percussive)) / (np.mean(np.abs(self.audio_data)) + 1e-8))\n",
    "            \n",
    "            # Voice detection using harmonic-percussive separation\n",
    "            self.features['vocal_harmonicity'] = float(np.mean(np.abs(y_harmonic)) / (np.mean(np.abs(y_percussive)) + 1e-8))\n",
    "            \n",
    "            # Extended instrument analysis using onset patterns\n",
    "            onset_frames = librosa.onset.onset_detect(y=self.audio_data, sr=self.sr)\n",
    "            onset_times = librosa.frames_to_time(onset_frames, sr=self.sr)\n",
    "            onset_env = librosa.onset.onset_strength(y=self.audio_data, sr=self.sr)\n",
    "            \n",
    "            if len(onset_times) > 1:\n",
    "                # Analyze onset patterns for rhythm section detection\n",
    "                onset_intervals = np.diff(onset_times)\n",
    "                self.features.update({\n",
    "                    'rhythm_regularity': float(1.0 / (np.std(onset_intervals) + 1e-8)),\n",
    "                    'rhythm_density': float(len(onset_times) / (self.audio_data.shape[0] / self.sr)),\n",
    "                    'drum_pattern_strength': float(np.mean(onset_env[onset_frames]))\n",
    "                })\n",
    "            else:\n",
    "                self.features.update({\n",
    "                    'rhythm_regularity': 0.0,\n",
    "                    'rhythm_density': 0.0,\n",
    "                    'drum_pattern_strength': 0.0\n",
    "                })\n",
    "\n",
    "            # Timbre classification using MFCCs\n",
    "            mfccs = librosa.feature.mfcc(y=self.audio_data, sr=self.sr, n_mfcc=13)\n",
    "            self.features.update({\n",
    "                'timbre_brightness': float(np.mean(mfccs[1:])),\n",
    "                'timbre_complexity': float(np.std(mfccs)),\n",
    "                'instrument_richness': float(np.mean(np.abs(librosa.feature.spectral_contrast(S=np.abs(S)))))\n",
    "            })\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def extract_vocal_features(self):\n",
    "        \"\"\"Extract vocal-specific features\"\"\"\n",
    "        with ResourceManager(\"Vocal Features\"):\n",
    "            # Only analyze vocals if they might be present\n",
    "            if self.features.get('vocals_presence', 0) > 0.3:\n",
    "                # Pitch variation for vocal analysis\n",
    "                pitches, magnitudes = librosa.piptrack(y=self.audio_data, sr=self.sr)\n",
    "                strong_pitches = pitches[magnitudes > np.mean(magnitudes) * 0.5]\n",
    "                \n",
    "                if len(strong_pitches) > 0:\n",
    "                    self.features.update({\n",
    "                        'vocal_pitch_range': float(np.ptp(strong_pitches)),\n",
    "                        'vocal_pitch_stability': float(1.0 / (np.std(strong_pitches) + 1e-8)),\n",
    "                        'vocal_vibrato': float(np.std(np.diff(strong_pitches)))\n",
    "                    })\n",
    "                else:\n",
    "                    self.features.update({\n",
    "                        'vocal_pitch_range': 0.0,\n",
    "                        'vocal_pitch_stability': 0.0,\n",
    "                        'vocal_vibrato': 0.0\n",
    "                    })\n",
    "                \n",
    "                # Vocal formant analysis\n",
    "                spectral_rolloff = librosa.feature.spectral_rolloff(y=self.audio_data, sr=self.sr)[0]\n",
    "                self.features.update({\n",
    "                    'vocal_formant_variation': float(np.std(spectral_rolloff)),\n",
    "                    'vocal_clarity': float(np.mean(librosa.feature.spectral_contrast(y=self.audio_data, sr=self.sr)[2:5]))\n",
    "                })\n",
    "            else:\n",
    "                self.features.update({\n",
    "                    'vocal_pitch_range': 0.0,\n",
    "                    'vocal_pitch_stability': 0.0,\n",
    "                    'vocal_vibrato': 0.0,\n",
    "                    'vocal_formant_variation': 0.0,\n",
    "                    'vocal_clarity': 0.0\n",
    "                })\n",
    "                \n",
    "            # Vocal range analysis\n",
    "            mel_spec = librosa.feature.melspectrogram(y=self.audio_data, sr=self.sr)\n",
    "            vocal_range = (200, 4000)  # Hz\n",
    "            vocal_band = np.logical_and(\n",
    "                librosa.mel_frequencies(n_mels=mel_spec.shape[0]) >= vocal_range[0],\n",
    "                librosa.mel_frequencies(n_mels=mel_spec.shape[0]) <= vocal_range[1]\n",
    "            )\n",
    "            self.features['Vocal_Presence'] = float(np.mean(mel_spec[vocal_band]) / np.mean(mel_spec))\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def extract_emotional_features(self):\n",
    "        \"\"\"Extract emotional content features\"\"\"\n",
    "        with ResourceManager(\"Emotional Features\"):\n",
    "            # Calculate spectral centroid for valence\n",
    "            S = librosa.stft(self.audio_data)\n",
    "            spectral_centroids = librosa.feature.spectral_centroid(S=np.abs(S), sr=self.sr)[0]\n",
    "            \n",
    "            # RMS energy for arousal\n",
    "            rms = librosa.feature.rms(y=self.audio_data)[0]\n",
    "            self.features['RMS_Energy_Mean'] = float(np.mean(rms))\n",
    "            self.features['RMS_Energy_Std'] = float(np.std(rms))\n",
    "            self.features['Dynamic_Range'] = float(np.max(rms) - np.min(rms))\n",
    "            self.features['Crest_Factor'] = float(np.max(np.abs(self.audio_data)) / np.sqrt(np.mean(self.audio_data**2)))\n",
    "            \n",
    "            # PCEN energy calculations\n",
    "            mel_spec = librosa.feature.melspectrogram(y=self.audio_data, sr=self.sr)\n",
    "            pcen = librosa.pcen(mel_spec)\n",
    "            self.features['PCEN_Energy_Mean'] = float(np.mean(pcen))\n",
    "            self.features['PCEN_Energy_Std'] = float(np.std(pcen))\n",
    "\n",
    "            # Calculate emotional features\n",
    "            self.features['Emotional_Valence'] = float(\n",
    "                0.5 * (np.mean(spectral_centroids) / (self.sr/2) + \n",
    "                       min(self.features['Tempo_BPM']/180, 1))\n",
    "            )\n",
    "            self.features['Emotional_Arousal'] = float(\n",
    "                0.5 * (np.mean(librosa.onset.onset_strength(y=self.audio_data, sr=self.sr)) + \n",
    "                       self.features['RMS_Energy_Mean'])\n",
    "            )\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def extract_pitch_features(self):\n",
    "        \"\"\"Extract pitch-related features\"\"\"\n",
    "        with ResourceManager(\"Pitch Features\"):\n",
    "            # Basic pitch extraction\n",
    "            pitches, magnitudes = librosa.piptrack(y=self.audio_data, sr=self.sr)\n",
    "            valid_pitches = pitches[magnitudes > np.mean(magnitudes) * 0.1]  # Filter weak pitches\n",
    "            \n",
    "            if len(valid_pitches) > 0:\n",
    "                self.features.update({\n",
    "                    'Average_Pitch': float(np.mean(valid_pitches)),\n",
    "                    'Pitch_Std': float(np.std(valid_pitches)),\n",
    "                    'Pitch_Range': float(np.ptp(valid_pitches))\n",
    "                })\n",
    "            else:\n",
    "                self.features.update({\n",
    "                    'Average_Pitch': 0.0,\n",
    "                    'Pitch_Std': 0.0,\n",
    "                    'Pitch_Range': 0.0\n",
    "                })\n",
    "            \n",
    "            # pYIN pitch features\n",
    "            try:\n",
    "                # Downsample audio for pYIN if it's long\n",
    "                if len(self.audio_data) > self.sr * 30:  # If longer than 30 seconds\n",
    "                    hop_length = 512  # Increased hop length for longer files\n",
    "                else:\n",
    "                    hop_length = 256  # Default hop length for shorter files\n",
    "                    \n",
    "                # Calculate pYIN with correct parameters\n",
    "                f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "                    self.audio_data,\n",
    "                    sr=self.sr,\n",
    "                    fmin=librosa.note_to_hz('C2'),  # Lower bound for pitch detection\n",
    "                    fmax=librosa.note_to_hz('C7'),  # Upper bound for pitch detection\n",
    "                    frame_length=2048,  # Reduced from default\n",
    "                    hop_length=hop_length,\n",
    "                    fill_na=None,  # Don't fill NaN values\n",
    "                    center=False  # Disable centering to save memory\n",
    "                )\n",
    "                \n",
    "                # Process only valid pitch values\n",
    "                valid_f0 = f0[voiced_flag]\n",
    "                if len(valid_f0) > 0:\n",
    "                    self.features.update({\n",
    "                        'pYIN_Mean_Pitch': float(np.mean(valid_f0)),\n",
    "                        'pYIN_Pitch_Std': float(np.std(valid_f0)),\n",
    "                        'pYIN_Pitch_Range': float(np.ptp(valid_f0)),\n",
    "                        'pYIN_Voiced_Rate': float(np.mean(voiced_flag)),\n",
    "                        'pYIN_Mean_Confidence': float(np.mean(voiced_probs))\n",
    "                    })\n",
    "                    \n",
    "                    # Additional pitch statistics only if we have enough data\n",
    "                    if len(valid_f0) > 10:\n",
    "                        # Calculate pitch stability\n",
    "                        pitch_changes = np.diff(valid_f0)\n",
    "                        self.features.update({\n",
    "                            'pYIN_Pitch_Stability': float(1.0 / (np.std(pitch_changes) + 1e-6)),\n",
    "                            'pYIN_Pitch_Clarity': float(np.max(voiced_probs) / (np.mean(voiced_probs) + 1e-6))\n",
    "                        })\n",
    "                    else:\n",
    "                        self.features.update({\n",
    "                            'pYIN_Pitch_Stability': 0.0,\n",
    "                            'pYIN_Pitch_Clarity': 0.0\n",
    "                        })\n",
    "                else:\n",
    "                    # Set default values if no valid pitch found\n",
    "                    self.features.update({\n",
    "                        'pYIN_Mean_Pitch': 0.0,\n",
    "                        'pYIN_Pitch_Std': 0.0,\n",
    "                        'pYIN_Pitch_Range': 0.0,\n",
    "                        'pYIN_Voiced_Rate': 0.0,\n",
    "                        'pYIN_Mean_Confidence': 0.0,\n",
    "                        'pYIN_Pitch_Stability': 0.0,\n",
    "                        'pYIN_Pitch_Clarity': 0.0\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"pYIN calculation failed: {str(e)}\")\n",
    "                self.features.update({\n",
    "                    'pYIN_Mean_Pitch': 0.0,\n",
    "                    'pYIN_Pitch_Std': 0.0,\n",
    "                    'pYIN_Pitch_Range': 0.0,\n",
    "                    'pYIN_Voiced_Rate': 0.0,\n",
    "                    'pYIN_Mean_Confidence': 0.0,\n",
    "                    'pYIN_Pitch_Stability': 0.0,\n",
    "                    'pYIN_Pitch_Clarity': 0.0\n",
    "                })\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def _add_mean_std_features(self, feature_name, feature_data):\n",
    "        \"\"\"Helper to add mean and std features for a data series\"\"\"\n",
    "        self.features[f'Average_{feature_name}'] = float(np.mean(feature_data))\n",
    "        self.features[f'{feature_name}_Std'] = float(np.std(feature_data))\n",
    "        \n",
    "    def _detect_key(self, chroma, y_harmonic):\n",
    "        \"\"\"\n",
    "        Key detection using Krumhansl-Schmuckler key-finding algorithm\n",
    "        \"\"\"\n",
    "        # Krumhansl-Schmuckler key profiles\n",
    "        major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
    "        minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
    "\n",
    "        # Normalize profiles\n",
    "        major_profile = major_profile / major_profile.sum()\n",
    "        minor_profile = minor_profile / minor_profile.sum()\n",
    "        \n",
    "        # Average and normalize chroma\n",
    "        mean_chroma = np.mean(chroma, axis=1)\n",
    "        mean_chroma = mean_chroma / (mean_chroma.sum() + 1e-8)\n",
    "        \n",
    "        # Initialize correlation scores\n",
    "        major_cors = []\n",
    "        minor_cors = []\n",
    "        \n",
    "        # Test all possible keys\n",
    "        for i in range(12):\n",
    "            # Rotate profiles to test each key\n",
    "            rolled_major = np.roll(major_profile, i)\n",
    "            rolled_minor = np.roll(minor_profile, i)\n",
    "            \n",
    "            # Calculate correlations\n",
    "            major_cor = np.corrcoef(mean_chroma, rolled_major)[0,1]\n",
    "            minor_cor = np.corrcoef(mean_chroma, rolled_minor)[0,1]\n",
    "            \n",
    "            major_cors.append(major_cor)\n",
    "            minor_cors.append(minor_cor)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        major_cors = np.array(major_cors)\n",
    "        minor_cors = np.array(minor_cors)\n",
    "        \n",
    "        # Find best key and mode\n",
    "        max_major_cor = np.max(major_cors)\n",
    "        max_minor_cor = np.max(minor_cors)\n",
    "        \n",
    "        if max_major_cor > max_minor_cor:\n",
    "            key_idx = np.argmax(major_cors)\n",
    "            mode = 'major'\n",
    "            confidence = max_major_cor\n",
    "        else:\n",
    "            key_idx = np.argmax(minor_cors)\n",
    "            mode = 'minor'\n",
    "            confidence = max_minor_cor\n",
    "        \n",
    "        # Map key index to key name\n",
    "        key_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "        key = key_names[key_idx]\n",
    "        \n",
    "        # Calculate confidence score (0-1)\n",
    "        # Compare best correlation to mean of other correlations\n",
    "        if mode == 'major':\n",
    "            others_mean = np.mean(np.delete(major_cors, key_idx))\n",
    "            confidence = (confidence - others_mean) / (1 - others_mean + 1e-8)\n",
    "        else:\n",
    "            others_mean = np.mean(np.delete(minor_cors, key_idx))\n",
    "            confidence = (confidence - others_mean) / (1 - others_mean + 1e-8)\n",
    "        \n",
    "        confidence = max(0, min(1, confidence))  # Clip to [0,1]\n",
    "        \n",
    "        return key, mode, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b840109-cbcb-4788-9dda-739082670806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# File Processing\n",
    "# ============================================================================\n",
    "\n",
    "class AudioFileProcessor:\n",
    "    \"\"\"Process audio files to extract features\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file_number = 0\n",
    "    \n",
    "    def set_file_number(self, number):\n",
    "        \"\"\"Set file number for tracking\"\"\"\n",
    "        self.file_number = number\n",
    "        return self\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Process audio file and extract features\"\"\"\n",
    "        try:\n",
    "            # Load audio data\n",
    "            audio_data, sample_rate = librosa.load(\n",
    "                self.file_path, \n",
    "                sr=None,  # Preserve original sample rate\n",
    "                mono=True,  # Convert to mono\n",
    "            )\n",
    "            \n",
    "            # Extract metadata\n",
    "            metadata_extractor = MetadataExtractor.create_extractor(self.file_path)\n",
    "            metadata = metadata_extractor.extract(self.file_path)\n",
    "            \n",
    "            # Extract features\n",
    "            feature_extractor = FeatureExtractor(audio_data, sample_rate)\n",
    "            features = feature_extractor.extract_all()\n",
    "            \n",
    "            # Combine metadata and features\n",
    "            analysis = {**metadata, **features}\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"\\nError analyzing {os.path.basename(self.file_path)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d59d57-142b-4d66-ae05-8cc10ec3d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Directory Processing\n",
    "# ============================================================================\n",
    "\n",
    "class DirectoryScanner:\n",
    "    \"\"\"Scan directories for audio files\"\"\"\n",
    "    \n",
    "    def __init__(self, root_path):\n",
    "        self.root_path = root_path\n",
    "    \n",
    "    def scan(self):\n",
    "        \"\"\"Recursively scan directory for supported audio files\"\"\"\n",
    "        audio_files = []\n",
    "        total_size = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"\\nScanning music directory...\")\n",
    "        print(\"This may take a while for large collections.\\n\")\n",
    "        \n",
    "        # Get total number of files for progress tracking\n",
    "        total_files = sum(len(files) for _, _, files in os.walk(self.root_path))\n",
    "        processed_files = 0\n",
    "        \n",
    "        for dirpath, dirnames, filenames in os.walk(self.root_path):\n",
    "            for filename in filenames:\n",
    "                processed_files += 1\n",
    "                if processed_files % 100 == 0:  # Update progress every 100 files\n",
    "                    elapsed = time.time() - start_time\n",
    "                    rate = elapsed / processed_files\n",
    "                    remaining = rate * (total_files - processed_files)\n",
    "                    \n",
    "                    progress = (processed_files / total_files) * 100\n",
    "                    print(f\"\\rScanning: {processed_files}/{total_files} files ({progress:.1f}%) | \"\n",
    "                          f\"ETA: {remaining/60:.1f}\", end='', flush=True)\n",
    "                    \n",
    "                ext = os.path.splitext(filename)[1].lower()\n",
    "                if AudioFormats.is_supported(ext):\n",
    "                    file_path = os.path.join(dirpath, filename)\n",
    "                    try:\n",
    "                        size = os.path.getsize(file_path)\n",
    "                        total_size += size\n",
    "                        audio_files.append({\n",
    "                            'path': file_path,\n",
    "                            'size': size,\n",
    "                            'parent_dir': os.path.basename(dirpath)\n",
    "                        })\n",
    "                    except OSError as e:\n",
    "                        logger.error(f\"\\nError accessing file {file_path}: {str(e)}\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\n\\nScan complete!\")\n",
    "        print(f\"Found {len(audio_files)} audio files\")\n",
    "        \n",
    "        return audio_files\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_audio_files(directory, track_selection='all'):\n",
    "        \"\"\"Get list of audio files based on selection\"\"\"\n",
    "        all_files = [f for f in os.listdir(directory) \n",
    "                     if os.path.splitext(f)[1].lower() in AudioFormats.FORMATS]\n",
    "        all_files.sort()\n",
    "        \n",
    "        if track_selection == 'all':\n",
    "            return all_files\n",
    "        \n",
    "        try:\n",
    "            if '-' in track_selection:\n",
    "                start, end = map(int, track_selection.split('-'))\n",
    "                return all_files[start-1:end]\n",
    "            else:\n",
    "                tracks = list(map(int, track_selection.split(',')))\n",
    "                return [f for i, f in enumerate(all_files, 1) if i in tracks]\n",
    "        except:\n",
    "            logger.warning(\"Invalid track selection. Using all tracks.\")\n",
    "            return all_files\n",
    "\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"Process batches of audio files with parallel processing\"\"\"\n",
    "    \n",
    "    def __init__(self, files, num_workers=None):\n",
    "        self.files = files\n",
    "        \n",
    "        if num_workers is None:\n",
    "            # Use 75% of available CPUs to avoid overwhelming system\n",
    "            self.num_workers = max(1, int(multiprocessing.cpu_count() * 0.75))\n",
    "        else:\n",
    "            self.num_workers = num_workers\n",
    "            \n",
    "        self.batch_size = 100  # Process files in chunks of 100\n",
    "        self.results = []\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Process all files in batches\"\"\"\n",
    "        total_files = len(self.files)\n",
    "        logger.info(f\"Processing {total_files} files with {self.num_workers} workers\")\n",
    "        \n",
    "        # Initialize progress tracker\n",
    "        progress = ProgressTracker(total_files, \"Analyzing audio files\")\n",
    "        \n",
    "        for i in range(0, total_files, self.batch_size):\n",
    "            batch = self.files[i:i + self.batch_size]\n",
    "            self._process_batch(batch, progress)\n",
    "            \n",
    "        return pd.DataFrame(self.results) if self.results else None\n",
    "    \n",
    "    def _process_batch(self, batch, progress):\n",
    "        \"\"\"Process a batch of files in parallel\"\"\"\n",
    "        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "            futures = {}\n",
    "            \n",
    "            for idx, file_info in enumerate(batch):\n",
    "                processor = AudioFileProcessor(file_info['path']).set_file_number(idx + 1)\n",
    "                futures[executor.submit(processor.process)] = file_info\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        with self.lock:\n",
    "                            self.results.append(result)\n",
    "                    progress.update()\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing {futures[future]['path']}: {str(e)}\")\n",
    "                    progress.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22351aef-2f4b-425b-b623-2f5bc346c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Output and Results\n",
    "# ============================================================================\n",
    "\n",
    "class ResultsManager:\n",
    "    \"\"\"Manage analysis results and output\"\"\"\n",
    "    \n",
    "    def __init__(self, results_df, music_directory):\n",
    "        self.results_df = results_df\n",
    "        self.music_directory = music_directory\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"Save results to CSV with organized directory structure\"\"\"\n",
    "        try:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            artist = self.results_df['Artist'].iloc[0] if 'Artist' in self.results_df.columns else 'Unknown'\n",
    "            analysis_type = 'library'\n",
    "            base_name = f\"{artist}_{analysis_type}\"\n",
    "            \n",
    "            # Clean name for filesystem\n",
    "            base_name = \"\".join(x for x in base_name if x.isalnum() or x in (' ', '-', '_')).strip()\n",
    "            \n",
    "            # Create directory structure\n",
    "            output_dir, data_dir = self._create_output_structure(\n",
    "                self.music_directory,\n",
    "                base_name,\n",
    "                timestamp\n",
    "            )\n",
    "            \n",
    "            # Save CSV in data directory\n",
    "            csv_path = os.path.join(data_dir, f\"{base_name}_{timestamp}.csv\")\n",
    "            self.results_df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            logger.info(f\"Results saved to: {csv_path}\")\n",
    "            return output_dir, data_dir, csv_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _create_output_structure(self, base_path, analysis_name, timestamp):\n",
    "        \"\"\"Create organized output directory structure\"\"\"\n",
    "        # Create main output directory\n",
    "        output_dir = os.path.join(base_path, f\"{analysis_name}_{timestamp}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        data_dir = os.path.join(output_dir, \"data\")\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        \n",
    "        return output_dir, data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95629b-27e3-4096-9796-12793846a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Main Application\n",
    "# ============================================================================\n",
    "\n",
    "class SpectralifyApp:\n",
    "    \"\"\"Main application class\"\"\"\n",
    "    \n",
    "    def __init__(self, music_directory):\n",
    "        self.music_directory = music_directory\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the full audio analysis workflow\"\"\"\n",
    "        try:\n",
    "            # Create Analysis directory at the root of music_directory\n",
    "            analysis_dir = os.path.join(self.music_directory, \"Analysis\")\n",
    "            os.makedirs(analysis_dir, exist_ok=True)\n",
    "            \n",
    "            # Scan for audio files\n",
    "            scanner = DirectoryScanner(self.music_directory)\n",
    "            audio_files = scanner.scan()\n",
    "            \n",
    "            if not audio_files:\n",
    "                logger.warning(\"No audio files found in the directory\")\n",
    "                return\n",
    "            \n",
    "            # Process files in batches\n",
    "            batch_size = 250\n",
    "            all_results = []\n",
    "            \n",
    "            for i in range(0, len(audio_files), batch_size):\n",
    "                batch = audio_files[i:i + batch_size]\n",
    "                \n",
    "                # Process batch\n",
    "                processor = BatchProcessor(batch)\n",
    "                results = processor.process()\n",
    "                \n",
    "                if results is not None:\n",
    "                    # Save directly to Analysis folder\n",
    "                    results_manager = ResultsManager(results, self.music_directory)\n",
    "                    results_manager.save_results()\n",
    "                \n",
    "                # Force garbage collection after each batch\n",
    "                gc.collect()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"Analysis interrupted by user\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5026b4d-920c-4b93-a96c-a14765b6d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Entry Point\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    # Get music directory from command line or use default\n",
    "    if len(sys.argv) > 1:\n",
    "        music_directory = sys.argv[1]\n",
    "    else:\n",
    "        # Default directory - change this to your music directory\n",
    "        music_directory = \"C://Users//Change//This//Path\"\n",
    "    \n",
    "    # Run the application\n",
    "    app = SpectralifyApp(music_directory)\n",
    "    app.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
